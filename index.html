<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>陈佳鑫 (Jiaxin Chen)</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>陈佳鑫 (Jiaxin Chen)</h1>
</div>
<table class="imgtable"><tr><td>
<a href="https://dr-jiaxin-chen.github.io/page/"><img src="profile_photo.png" alt="alt text" width="120px" /></a>&nbsp;</td>
<td align="left"><p>Associate Professor<br />
<a href="http://scse.buaa.edu.cn/">School of Computer Science and Engineering</a> <br />
<a href="https://www.buaa.edu.cn/">Beihang University</a> <br />
Beijing 100191, China <br />
Email: jiaxinchen@buaa.edu.cn <br />
<br />
<a href="http://shi.buaa.edu.cn/chenjiaxin/zh_CN/index.htm">[Resume]</a> <a href="https://scholar.google.pl/citations?user=eNlGf7EAAAAJ&hl=en">[Google Scholar]</a> 
  <a href="https://github.com/Dr-Jiaxin-Chen">[GitHub]<a href="http://shi.buaa.edu.cn/chenjiaxin/zh_CN/index.htm">[Chinese Page]</a></p>
</td></tr></table>
<h2>Brief Introduction</h2>
<p>
Dr. Jiaxin Chen received his Ph.D. degree in Computer Applications Technology from Beihang University in 2017. From 2017 to 2018, he was a Postdoctoral Fellow at New York University Abu Dhabi (NYUAD). From 2018 to 2021, he was a research scientist at Inception Institute of Artificial Intelligence (IIAI). His current research interests include efficient training and inference on large multi-modal fundamental models and visual perception for unmanned systems. He has authored/co-authored over 20 papers in top-tier conferences/journals such as IEEE Transactions on Pattern Analysis and Machine Intelligence (IEEE TPAMI), IEEE Transactions on Image Processing (IEEE TIP), CVPR, ICCV, ECCV and NeurIPS.</p>
<h2>Research Interests</h2>
<ul>
<li>
<p><b>Efficient Training and Inference on Large Fundamental Models</b>: Parameter-Efficient Fine-Tuning (PEFT) <a href="https://dr-jiaxin-chen.github.io/page/project/PEFT.html">[project]</a>; Deep Model Compression (Pruning, Quantization, Distilling) <a href="https://dr-jiaxin-chen.github.io/page/project/DMC.html">[project]</a></p>
</li>
<li>
<p><b>Visual Perception for Unmanned Systems</b> (e.g. Drones or Autonomous Cars): Object Detection/Tracking <a href="https://dr-jiaxin-chen.github.io/page/project/VPUS.html">[project]</a></p>
</li>
<li>
<p><b>Imagery/Video Analysis</b>: Object Re-Identificatioin/Search/Retrieval <a href="https://dr-jiaxin-chen.github.io/page/project/VOS.html">[project]</a>；Compressed Video Analysis <a href="https://dr-jiaxin-chen.github.io/page/project/CVA.html">[project]</a></p>
</li>
<li>
<p><b>Machine Learning</b>: Transfer Learning; Self-Supervised Learning; Metric Learning</p>
</li>
<li>
<p><b>3D Computer Vision</b>: 3D Object Representation/Recognition/Retrieval</p>
</li>
</ul>
<h2>News</h2>
<ul>
<li>
(2026/01）Four papers with titles “Collaborative Multi-Mode Pruning for Vision-Language Models”, “Memory-Efficient Transfer Learning with Fading Side Networks via Masked Dual Path Distillation”, “Parameter-Efficient Adaptation for MLLMs via Implicit Modality Decomposition” and “Visual Prototype Conditioned Focal Region Generation for UAV-Based Object Detection” are accepted by CVPR 2026. Congratulations to Zimeng Wu, Yutong Zhang, Mingfang Zhang and Wenhao Li！
</li> 
<li>
(2026/01）One paper with title “Towards Accurate Quantization for Large Vision-Language Models via Zeroth-Order Gradient Optimization and Sectioned Logarithmic Quantizer” is accepted by ICASSP 2026. Congratulations to Jiayi Zhang！
</li> 
</ul>
<h2>Positions for Master/PhD's Programme</h3>
<ul>
<li>
We are looking for students, who are <font color="red">self-motivated</font>, and have <font color="red">solid 
  foundation in mathematics and programming</font>. Please feel free to contact us at <font color="blue">jiaxinchen@buaa.edu.cn</font>.   
</ul> 
<h2>Preprints</h2>
<ul>
<li>
<p><a href="https://arxiv.org/abs/2601.13155">Probe and Skip: Self-Predictive Token Skipping for Efficient Long-Context LLM Inference</a><br />
Z. Wu, D. Wang, C. Jin, <b>J. Chen</b> and Y. Wang<br />
<i>Arxiv.</i> <a href="https://arxiv.org/pdf/2601.13155">[Paper]</a></p>
</li> 
<li>
<p>Parameter-Efficient Tuning for Fine-Grained Recognition via Channel-wise Importance Equalization and Diversity Navigation</a><br />
H. Zhong, <b>J. Chen</b>, Y. Zhang, D. Huang and Y. Wang<br />
<i>IEEE Transactions on Image Processing (IEEE TIP).</i> Minor revision</p>
</li> 
</ul> 
<h2>Publications <font size=1>(* indicates equal contribution. &#9993 indicates corresponding author)</font></h2>   
<h3>2026</h3>
<h4>Conferences</h4>
<ul>
<li>
<p><a href="TBD">Collaborative Multi-Mode Pruning for Vision-Language Models</a> <br />
Z. Wu, Y. Wang, D. Wang and <b>J. Chen</b><br />  
<i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2026. Accepted.</i>
</li>  
<p><a href="TBD">Memory-Efficient Transfer Learning with Fading Side Networks via Masked Dual Path Distillation</a> <br />
Y. Zhang, <b>J. Chen</b>, H. Chen, K. Zheng, S. Liao, H. Zhong, W. Li and Y. Wang<br />  
<i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2026. Accepted.</i>
</li>  
</li>  
<p><a href="TBD">Parameter-Efficient Adaptation for MLLMs via Implicit Modality Decomposition</a> <br />
M. Zhang, Y. Wang, L. Wang and <b>J. Chen</b><br />  
<i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2026. Accepted.</i>
</li>  
</li>  
<p><a href="TBD">Visual Prototype Conditioned Focal Region Generation for UAV-Based Object Detection</a> <br />
W. Li, M. Wu, Y. Wu, Z. Fu and <b>J. Chen</b><br />  
<i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2026. Accepted.</i>
</li>  
<li>
<p><a href="TBD">Towards Accurate Quantization for Large Vision-Language Models via Zeroth-Order Gradient Optimization and Sectioned Logarithmic Quantizer</a> <br />
J. Zhang, <b>J. Chen<sup>&#9993</sup></b>, X. Guo, X. Tong and D. Huang<br />  
<i>International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2026. </i>
</li>  
<li>
<p><a href="TBD">MP-ISMoE: Mixed-Precision Interactive Side Mixture-of-Experts for Efficient Transfer Learning</a> <br />
Y. Zhang, Z. Wu, S. Liao, S. Wu and <b>J. Chen<sup>&#9993</sup></b><br />  
<i>AAAI Conference on Artificial Intelligence (AAAI), 2026.
</li>    
</ul> 
<h4>Journals</h4>
<ul>
<li><p><a href="https://link.springer.com/article/10.1007/s44267-026-00109-1">DAS-SAM: Fine-tuning SAM Towards Drivable Area Segmentation via Efficient Multi-scale Traffic Scene-aware Adaptation</a> <br />
Z. Chen, N. Zhou, Y. Fan, L. Zhou, Y. Xie, <b>J. Chen<sup>&#9993</b> and D. Huang<br />
<i>Visual Intelligence, vol. 4, no. 6, pp. 1-13, 2026.</i><a href="https://link.springer.com/article/10.1007/s44267-026-00109-1">[Paper]</a></p>
</li> 
<li><p><a href="">分布范围动态感知的扩散模型量化</a> <br />
占瑞乙, 樊轶, 周丽娜, 谢宇宝, <b>陈佳鑫<sup>&#9993</b>, 杨鸿宇, 黄迪, 王蕴红<br />
<i>中国图象图形学报, 2026. (录用, CCF T2类期刊)</i><a href="https://link.springer.com/article/10.1007/s44267-026-00109-1">[Paper]</a></p>
</li>   
</ul>  
<h3>2025</h3>
<h4>Conferences</h4>
<ul>
<li>
<p><a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_APHQ-ViT_Post-Training_Quantization_with_Average_Perturbation_Hessian_Based_Reconstruction_for_CVPR_2025_paper.pdf">APHQ-ViT: Post-Training Quantization with Average Perturbation Hessian Based Reconstruction for Vision Transformers</a> <br />
Z. Wu, J. Zhang, <b>J. Chen<sup>&#9993</sup></b>, J. Guo, D. Huang and Y. Wang<sup>&#9993</sup><br />  
<i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2025. </i><a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_APHQ-ViT_Post-Training_Quantization_with_Average_Perturbation_Hessian_Based_Reconstruction_for_CVPR_2025_paper.pdf">[Paper]</a><a href="https://github.com/GoatWu/APHQ-ViT">[Code]</a></p>
</li>  
<li>
<p><a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_FIMA-Q_Post-Training_Quantization_for_Vision_Transformers_by_Fisher_Information_Matrix_CVPR_2025_paper.pdf">FIMA-Q: Post-Training Quantization for Vision Transformers by Fisher Information Matrix Approximation</a> <br />
Z. Wu, S. Wang, J. Zhang, <b>J. Chen<sup>&#9993</sup></b> and Y. Wang<sup>&#9993</sup><br />  
<i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2025. </i><a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Wu_FIMA-Q_Post-Training_Quantization_for_Vision_Transformers_by_Fisher_Information_Matrix_CVPR_2025_paper.pdf">[Paper]</a><a href="https://github.com/ShiheWang/FIMA-Q">[Code]</a></p>
</li> 
<li>
<p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/33913">TCAQ-DM: Timestep-Channel Adaptive Quantization for Diffusion Models</a> <br />
H. Huang*, <b>J. Chen</b>*, J. Guo, R. Zhan and Y. Wang<br />
<i>AAAI Conference on Artificial Intelligence (AAAI), 2025. </i><a href="https://ojs.aaai.org/index.php/AAAI/article/view/33913/36068">[Paper]</a><a href="https://arxiv.org/pdf/2412.16700">[Supplementary Material]</a></p>
</li>  
<li>
<p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/32923">Unified Knowledge Maintenance Pruning and Progressive Recovery with Weight Recalling for Large Vision-Language Models</a> <br />
Z. Wu, <b>J. Chen<sup>&#9993</b> and Y. Wang <br />
<i>AAAI Conference on Artificial Intelligence (AAAI), 2025. </i><a href="https://ojs.aaai.org/index.php/AAAI/article/view/32923/35078">[Paper]</a><a href="https://github.com/Wuzimeng/UKMP">[Code]</a></p>
</li>  
<li>
<p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/32789">3D2-Actor: Learning Pose-Conditioned 3D-Aware Denoiser for Realistic Gaussian Avatar Modeling</a> <br />
Z. Tang, H. Yang, H. Zhang, <b>J. Chen</b> and D. Huang <br />
<i>AAAI Conference on Artificial Intelligence (AAAI), 2025. </i><a href="https://ojs.aaai.org/index.php/AAAI/article/view/32789/34944">[Paper]</a><a href="https://github.com/silence-tang/GaussianActor">[Code]</a></p>
</li> 
</ul>
<h4>Journals</h4>
<ul>
<li><p><a href="">基于动态查询注意力及显著词元增强的航拍图像目标检测</a> <br />
张宇骏, 唐超, 樊轶, 周丽娜, 谢宇宝, <b>陈佳鑫<sup>&#9993</b><br />
<i>航空科学基金40周年论文集, pp. 260-267, 2025.</i><a href=" ">[Paper]</a></p>
</li> 
<li><p><a href="https://ieeexplore.ieee.org/document/11080224">Cross-modal Contrastive Masked AutoEncoder for Compressed Video Pre-training</a> <br />
B. Li, <b>J. Chen<sup>&#9993</b>, G. Li, D. Zhang, X. Bao and D. Huang  <br />
<i>IEEE Transactions on Image Processing (TIP), vol. 34, pp. 4500-4514, 2025. </i><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=11080224">[Paper]</a></p>
</li>
<li><p><a href="https://ieeexplore.ieee.org/document/11080247">Sharing Task-relevant Information in Visual Prompt Tuning by Cross-layer Dynamic Connection</a> <br />
N. Zhou <b>J. Chen<sup></b> and D. Huang  <br />
<i>IEEE Transactions on Image Processing (TIP), vol. 34, pp. 4527-4540, 2025. </i><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=11080247">[Paper]</a></p>
</li>
<li><p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0010448525001150">Self-supervised representation of non-standard mechanical parts and fine-tuning method integrating macro process knowledge</a> <br />
Z. Li, M. Cai, <b>J. Chen<sup></b>, F. Ning, Z. Xie and X. Tong  <br />
<i>Computer-Aided Design, vol. 189, 2025. </i><a href="https://www.sciencedirect.com/science/article/abs/pii/S0010448525001150">[Paper]</a></p>
</li>
</ul>
<h3>2024</h3>
<h4>Conferences</h4>
<ul>
<li>
<p><a href="https://neurips.cc/virtual/2024/poster/94890">Transforming Vision Transformer: Towards Efficient Multi-Task Asynchronous Learner</a> <br />
H. Zhong, <b>J. Chen<sup>&#9993</b>, Y. Zhang, D. Huang and Y. Wang <br />
<i>Annual Conference on Neural Information Processing Systems (NeurIPS), 2024. </i><a href="https://proceedings.neurips.cc/paper_files/paper/2024/file/93fab021315170101c92e8330a56fbdb-Paper-Conference.pdf">[Paper]</a><a href="https://github.com/Yewen1486/EMTAL">[Code]</a></p>
</li>  
<li>
<p><a href="https://dl.acm.org/doi/10.1145/3688863.3689576">Domain Adaptive Object Detection for UAV-based Images by Robust Representation Learning and Multiple Pseudo-label
Aggregation</a> <br />
K. Wu, <b>J. Chen<sup>&#9993</b> and <b>M. Wang<sup>&#9993</b>  <br />
<i>ACM International Conference on Multimedia (MM) Workshops, 2024. </i><a href="https://dl.acm.org/doi/pdf/10.1145/3688863.3689576">[Paper]</a></p>
</li>
</ul>  
<ul>
<li>
<p><a href="https://link.springer.com/chapter/10.1007/978-3-031-73383-3_24">AdaLog: Post-Training Quantization for Vision Transformers with Adaptive Logarithm Quantizer</a> <br />
Z. Wu, <b>J. Chen<sup>&#9993</b>, H. Zhong, D. Huang and Y. Wang  <br />
<i>European Conference on Computer Vision (ECCV), 2024. </i><a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/03969.pdf">[Paper]</a><a href="https://github.com/GoatWu/AdaLog">[Code]</a></p>
</li>
</ul> 
<h4>Journals</h4>
<ul>
<li><p><a href="https://link.springer.com/article/10.1007/s11263-024-02313-2">CMAE-3D: Contrastive Masked AutoEncoders for Self-Supervised 3D Object Detection</a> <br />
Y. Zhang, <b>J. Chen</b> and D. Huang <br />
<i>International Journal of Computer Vision (IJCV), 2024. Accepted.</i><a href="https://link.springer.com/content/pdf/10.1007/s11263-024-02313-2.pdf">[Paper]</a></p>
</li>
</ul>  
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/10599208">OTAMatch: Optimal Transport Assignment with PseudoNCE for Semi-supervised Learning</a> <br />
J. Zhang, J. Liu, D. Li, Q. Huang, <b>J. Chen</b> and D. Huang <br />
<i>IEEE Transactions on Image Processing (TIP), vol. 33, pp. 4231-4244, 2024. </i><a href="https://ieeexplore.ieee.org/document/10599208">[Paper]</a></p>
</li>
</ul> 
<h3>2023</h3>
<h4>Conferences</h4>  
<ul>
<li>
<p><a href="https://openreview.net/pdf?id=2vADOf3K00">Compressed Video Prompt Tuning</a> <br />
B. Li, <b>J. Chen</b>, X. Bao and D. Huang  <br />
<i>Annual Conference on Neural Information Processing Systems (NeurIPS), 2023. </i><a href="https://openreview.net/pdf?id=2vADOf3K00">[Paper]</a></p>
</li>
<li>
<p><a href="https://dl.acm.org/doi/10.1007/978-981-99-8549-4_17">SAMP: Sub-task Aware Model Pruning with Layer-wise Channel Balancing for Person Search</a> <br />
Z. Wu, <b>J. Chen<sup>&#9993</b> and Y. Wang  <br />
<i>Chinese Conference on Pattern Recognition and Computer Vision (PRCV), 2023. </i><a href="TBD">[Paper]</a></p>
</li>
<li>
<p><a href="https://dl.acm.org/doi/10.1145/3581783.3612563">MIEP: Channel Pruning with Multi-granular Importance Estimation for Object Detection</a> <br />
L. Jiang, <b>J. Chen<sup>&#9993</b>, D. Huang and Y. Wang  <br />
<i>ACM International Conference on Multimedia (MM), 2023. </i><a href="https://dl.acm.org/doi/pdf/10.1145/3581783.3612563">[Paper]</a></p>
</li>
<li>
<p><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_DR-Tune_Improving_Fine-tuning_of_Pretrained_Visual_Models_by_Distribution_Regularization_ICCV_2023_paper.pdf">DR-Tune: Improving Fine-tuning of Pretrained Visual Models by Distribution Regularization with Semantic Calibration</a> <br />
N. Zhou, <b>J. Chen</b> and D. Huang <br />
<i>IEEE International Conference on Computer Vision (ICCV), 2023. </i><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_DR-Tune_Improving_Fine-tuning_of_Pretrained_Visual_Models_by_Distribution_Regularization_ICCV_2023_paper.pdf">[Paper]</a></p>
</li>
<li>
<p><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Du_Adaptive_Sparse_Convolutional_Networks_With_Global_Context_Enhancement_for_Faster_CVPR_2023_paper.pdf">Adaptive Sparse Convolutional Networks with Global Context Enhancement for Faster Object Detection on Drone Images</a> <br />
B. Du, Y. Huang, <b>J. Chen</b> and D. Huang <br />
<i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023. </i><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Du_Adaptive_Sparse_Convolutional_Networks_With_Global_Context_Enhancement_for_Faster_CVPR_2023_paper.pdf">[Paper]</a></p>
</li>
<li>
<p><a href="https://www.engineeringvillage.com/app/doc/?docid=cpx_M4429324b1876cbc45a8M7de910178165143&pageSize=25&index=1&searchId=0945ad8f51394f7d9a7794b9e4f75475&resultsCount=2&usageZone=resultslist&usageOrigin=searchresults&searchType=Quick">OcTr: Octree-based Transformer for 3D Object Detection</a> <br />
C. Zhou, Y. Zhang, <b>J. Chen</b> and D. Huang <br />
<i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023. </i><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_OcTr_Octree-Based_Transformer_for_3D_Object_Detection_CVPR_2023_paper.pdf">[Paper]</a>
</p>
</li>
</ul>
<h4>Journals</h4>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/9233968/citations#citations">Learning Multi-Attention Context Graph for Group-Based Re-Identification</a> <br />
Y. Yan, J. Qin, B. Ni, <b>J. Chen</b>, L. Liu, F. Zhu, W. Zheng, X. Yang and L. Shao. <br />
<i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), vol. 45, no. 6, pp: 7001-7018, 2023. </i><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9233968">[Paper]</a></p>
</li>
</ul>    
<h3>2022</h3>
<h4>Conferences</h4>  
<ul>
<li><p><a href="https://www.ijcai.org/proceedings/2022/0148.pdf">Representation Learning for Compressed Video Action Recognition via Attentive Cross-modal Interaction with Motion Enhancement</a> <br />
B. Li, <b>J. Chen<sup>&#9993</b>, D. Zhang, X. Bao and D. Huang <br />
<i>International Joint Conference on Artificial Intelligence (IJCAI), 2022. </i><a href="https://www.ijcai.org/proceedings/2022/0148.pdf">[Paper]</a></p>
</li>
<li><p><a href="https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_CAT-Det_Contrastively_Augmented_Transformer_for_Multi-Modal_3D_Object_Detection_CVPR_2022_paper.html">CAT-Det: Contrastively Augmented Transformer for Multi-modal 3D Object Detection</a> <br />
Y. Zhang, <b>J. Chen</b> and D. Huang <br />
<i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022. </i><a href="https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_CAT-Det_Contrastively_Augmented_Transformer_for_Multi-Modal_3D_Object_Detection_CVPR_2022_paper.html">[Paper]</a></p>
</li>
<li><p><a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Target-Relevant_Knowledge_Preservation_for_Multi-Source_Domain_Adaptive_Object_Detection_CVPR_2022_paper.pdf">Target-Relevant Knowledge Preservation for Multi-Source Domain Adaptive Object Detection</a> <br />
J. Wu, <b>J. Chen<sup>&#9993</b>, M. He, Y. Wang, B. Li, B. Ma, W. Gan, W. Wu, Y. Wang and D. Huang <br />
<i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022. </i><a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Target-Relevant_Knowledge_Preservation_for_Multi-Source_Domain_Adaptive_Object_Detection_CVPR_2022_paper.pdf">[Paper]</a></p>
</li>
<li><p><a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Entropy-Based_Active_Learning_for_Object_Detection_With_Progressive_Diversity_Constraint_CVPR_2022_paper.pdf">Entropy-based Active Learning for Object Detection with Progressive Diversity Constraint</a> <br />
J. Wu, <b>J. Chen</b> and D. Huang <br />
<i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022. </i><a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Entropy-Based_Active_Learning_for_Object_Detection_With_Progressive_Diversity_Constraint_CVPR_2022_paper.pdf">[Paper]</a></p>
</li>
<li><p><a href="https://arxiv.org/pdf/2112.10415v2.pdf">UFPMP-Det: Toward Accurate and Efficient Object Detection on Drone Imagery</a> <br />
Y. Huang, <b>J. Chen</b> and D. Huang <br />
<i>AAAI Conference on Artificial Intelligencen (AAAI), 2022. </i><a href="https://arxiv.org/pdf/2112.10415v2.pdf">[Paper]</a></p>
</li>
</ul>
<h4>Journals</h4>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/9817378">Video Person Re-identification Using Attribute-enhanced Features</a> <br />
T. Chai, Z. Chen, A. Li, <b>J. Chen</b>, X. Mei, Y. Wang <br />
<i>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), vol. 32, no. 11, pp: 7951-7966, 2022. </i><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9817378">[Paper]</a></p>
</li>
<li><p><a href="https://www.sciencedirect.com/science/article/pii/S0097849322001261?dgcid=coauthor">SHREC’22 Track: Sketch-Based 3D Shape Retrieval in the Wild</a> <br />
J. Qin, S. Yuan, <b>J. Chen</b>, et al. <br />
<i>Computers & Graphics (CAG), vol. 107, pp: 104-115, 2022. </i><a href="https://www.sciencedirect.com/science/article/pii/S0097849322001261/pdfft?crasolve=1&r=74266d514d169440&ts=1661788065507&rtype=https&vrr=UKN&redir=UKN&redir_fr=UKN&redir_arc=UKN&vhash=UKN&host=d3d3LnNjaWVuY2VkaXJlY3QuY29t&iv=3fc0b0a3a58d93e36ea7363909204a6f&token=66666439613464316438616362323664646335626333336564336534393762316361663330313366306230666261353965346235646339626334313833613666613539353a386232356437633631363839356363643637636365353663&text=c323c076bac6b0667c45ca5920ba551e1b1ce05c449295348e0dc5deecb8fa622ecf23f1bba40b4197293a09f17854064a8bc6df3d353b5eac07dcc12cbd149eb04e184e85f742636298f02078eabfcc5ec9a06686909ccea881b9be42fbd05ad9aafec59164920d862c3cb2ec0611c6e7a275900d1a3a29275b71a8118e0323cb43a1ea934b670f7a596434ffa5e00483c8f5968997d936832c3a9a4a5e09da9c9550243627c892bae370d2846de22f096c5b34bd289973d26e9a03a8182808de595d99ead0ca370311438a687de84d28e2d90b737ea2f07e36114f04bf302b961cac7fd175150c82939a11f09f94dcadc1fe3e103f854434e96dadf8b6a690965dd38e93e0fe3d9c5245866755d235a7561de51e48c594dbd2a6337642a44a9107dffc634af57de96a2d507569a35b&original=3f6d64353d6231323637643939366365613465636562396365623037663237333863643839267069643d312d73322e302d53303039373834393332323030313236312d6d61696e2e706466">[Paper]</a></p>
</li>
</ul>
<h3>2021</h3>
<h4>Conferences</h4>  
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/9711034/">PR-GCN: A Deep Graph Convolutional Network with Point Refinement for 6D Pose Estimation</a> <br />
G. Zhou, H. Wang, <b>J. Chen</b> and D. Huang <br />
<i> IEEE International Conference on Computer Vision (ICCV), 2021. </i><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9711034&tag=1">[Paper]</a></p>
</li>
</ul>
<h3>2020</h3>
<h4>Conferences</h4>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/9157770">Auto-Encoding Twin-Bottleneck Hashing</a> <br />
Y. Shen*, J. Qin*, <b>J. Chen</b>*, M. Yu, L. Liu, F. Zhu, F. Shen and L. Shao <br />
<i> IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020. </i><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9157770">[Paper]</a></p>
</li>
<li><p><a href="https://ieeexplore.ieee.org/document/9156659">Learning Multi-Granular Hypergraphs for Video-Based Person Re-Identification</a> <br />
Y. Yan, J. Qin, <b>J. Chen</b>, L. Liu, F. Zhu, Y. Tai and L. Shao <br />
<i> IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020. </i><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9156659">[Paper]</a></p>
</li>
<li><p><a href="http://dl.acm.org/doi/pdf/10.1145/3394171.3413979">Deep Local Binary Coding for Person Re- Identification by Delving into the Details</a> <br />
<b>J. Chen</b>, J. Qin, Y. Yan, L. Huang, L. Liu, F. Zhu and L. Shao <br />
<i> ACM International Conference on Multimedia (MM), 2020. </i><a href="http://dl.acm.org/doi/pdf/10.1145/3394171.3413979">[Paper]</a></p>
</li>
<li><p><a href="https://link.springer.com/chapter/10.1007/978-3-030-58555-6_7">Learning Attentive and Hierarchical Representations for 3D Shape Recognition</a> <br />
<b>J. Chen</b>, J. Qin, Y. Shen, L. Liu, F. Zhu and L. Shao <br />
<i> European Conference on Computer Vision (ECCV), 2020. </i><a href="https://link.springer.com/content/pdf/10.1007/978-3-030-58555-6.pdf">[Paper]</a></p>
</li>
<li><p><a href="https://ieeexplore.ieee.org/document/9102790">Web-Supervised Network for Fine- Grained Visual Classification</a> <br />
C. Zhang, Y. Yao, J. Zhang, <b>J. Chen</b>, P. Huang, J. Zhang and Z. Tango <br />
<i> IEEE International Conference on Multimedia and Expo (ICME), 2020. </i><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9233968">[Paper]</a></p>
</li>
</ul>
<h4>Journals</h4>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/8957359">Zero-VAE-GAN: Generating Unseen Features for Generalized and Transductive Zero-Shot Learning</a> <br />
R. Gao, X. Hou, J. Qin, <b>J. Chen</b>, L. Liu, F. Zhu, Z. Zhang and L. Shao. <br />
<i>IEEE Transactions on Image Processing (TIP), vol. 29, pp: 3665-3680, 2020. </i><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8957359">[Paper]</a></p>
</li>
</ul>
<h3>2019</h3>
<h4>Conferences</h4>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/8954192">Deep Sketch-Shape Hashing with Segmented 3D Stochastic Viewing</a> <br />
<b>J. Chen</b>, J. Qin, L. Liu, F. Zhu, F. Shen, J. Xie and L. Shao <br />
<i> IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019. </i><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8954192">[Paper]</a></p>
</li>
</ul>
<h3>2018</h3>
<h4>Conferences</h4>
<ul>
<li><p><a href="http://link.springer.com/chapter/10.1007/978-3-030-01261-8_37">Deep Cross-modality Adaptation via Semantics Preserving Adversarial Learning for Sketch-based 3D Shape Retrieval</a> <br />
<b>J.Chen</b> and Y. Fang <br />
<i> European Conference on Computer Vision (ECCV), 2018. </i><a href="https://link.springer.com/content/pdf/10.1007/978-3-030-01261-8.pdf">[Paper]</a></p>
</li>
</ul>
<h4>Journals</h4>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/8067648">GII Representation-Based Cross-View Gait Recognition by Discriminative Projection With List-Wise Constraints</a> <br />
Z. Zhang, <b>J. Chen<sup>&#9993</b>, Q. Wu and L. Shao. <br />
<i>IEEE Transactions on Cybernetics (TCYB), vol. 48, no. 10, pp: 2935-2947, 2018. </i><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8067648">[Paper]</a></p>
</li>
</ul>
<h3>2017</h3>
<h4>Conferences</h4>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/8100049">Fast Person Re-identification via Cross-Camera Semantic Binary Transformation</a> <br />
<b>J. Chen</b>, Y. Wang, J. Qin, L. Liu and L. Shao <br />
<i> IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017. </i><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8100049">[Paper]</a></p>
</li>
</ul>
<h3>2015</h3>
<h4>Journals</h4>
<ul>
<li><p><a href="https://ieeexplore.ieee.org/document/7182350">Relevance Metric Learning for Person Re-Identification by Exploiting Listwise Similarities</a> <br />
<b>J. Chen</b>, Z. Zhang and Y. Wang. <br />
<i>IEEE Transactions on Image Processing (TIP), vol. 24, no. 12, pp: 4741-4755, 2015. </i><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7182350">[Paper]</a></p>
</li>
</ul>
<h2>Patents</h2>  
<ul>
<li>
<b>陈佳鑫</b>, 黄浩程, 郭晋阳, 占瑞乙, 王蕴红. 一种时间步自适应的扩散模型训练后量化方法. ZL202411769042.1, 2025. (已授权)
</li>  
<li>
<b>陈佳鑫</b>, 张宇彤, 陈鸿林, 王蕴红. 基于紧致表征建模和语义标签引导的细粒度图像检索方法. ZL202510002116.7, 2025. (已授权)
</li>  
<li>
<b>陈佳鑫</b>, 江良伟, 王蕴红. 一种基于多粒度重要性度量的图像表征模型剪枝方法. ZL202311222095.7, 2025. (已授权)
</li> 
<li>
<b>陈佳鑫</b>, 吴梓萌, 王蕴红. 一种面向深度行人搜索模型的结构化剪枝方法. ZL202311235935.3, 2025. (已授权)
</li>  
<li>
<b>陈佳鑫</b>, 周辰育, 王蕴红. 基于特征自适应对齐融合的多视角航拍图像目标检测方法. 202511559527.2, 2025. (已受理)
</li>  
<li>
<b>陈佳鑫</b>, 周辰育, 王蕴红. 基于频域解耦多尺度特征融合的航拍图像目标检测方法. 202511559155.3, 2025. (已受理)
</li>  
</ul>
<h2>Teams</h2>
<h3>Ph.D Students</h3>
<ul>
<li>
Zimeng Wu (Co-advise with Prof. Yunhong Wang)  |  Research topic: Efficient Training and Inference of Large Multi-modal Foundation model  | (AAAI'25, CVPR'26)
</li>
</ul>
<h3>Master Students</h3>
<h4>Enrolled in 2023</h3>
<ul>
<li>
Wenhao Li  |  Research topic: UAV-based Intelligent Perception  | (CVPR'26)
</li>
<li>
Yutong Zhang  |  Research topic: Memory Efficient Transfer Learning  | (AAAI'26, CVPR'26)
</li>
</li>
</ul>
<h4>Enrolled in 2024</h3>
<ul>
<li>
Honglin Chen  |  Research topic: Parameter Efficient Transfer Learning
</li>
<li>
Chaozhe Jin  |  Research topic: Efficient Inference of Generative Models
</li>
<li>
Zeyuan Ma  |  Research topic: Vision-and-Language Navigation for UAVs
</li>
<li>
Ke Wu  |  Research topic: UAV-based Intelligent Perception  | (ACM MM Workshops'24)
</li>
<li>  
Kaiqi Zheng  |  Research topic: Foundation Vision-Language Models for Autonomous Driving
</li>
<li>  
Mingfang Zhang  |  Research topic: Parameter-Efficient Adaptation  | (CVPR'26)
</li>
</ul>
<h4>Enrolled in 2025</h3>
<ul>
<li>
Donghao Wang  |  Research topic: Efficient Inference for Foundemetal Models
</li>
<li>
Yihui Wang
</li>
<li>
Yujun Zhang
</li>
</ul>
<h3>Undergraduate Students</h3>
<h4>Undergraduate Thesis 2025</h3>  
<ul>
<li>
Jiayi Zhang  |  Research topic: Quantization for Large Tranformers-based Models;
Yujun Zhang  |  Research topic: Object Detection on Drone Images based on Foundamental Models;
Chenjue Zhang  |  Research topic: Domain Adaptive Object Detection on Drone Images;
</li>
</ul>
<h4>Undergraduate Thesis in 2024</h3>
<ul>
<li>
Zhenghao Chen (Parameter-Efficient Fine-Tuning); 
Ke Wu (UAV-based Intelligent Perception); 
Ruiyi Zhan (Quantization for Deep Diffussion Models); 
Mingfang Zhang (BEV-based 3D Ojbect Detection).
</li>
</ul>
<h3>Alumni</h3>
<ul>
<li>
Shihe Wang (Co-advise with Prof. Yunhong Wang) (CVPR'25) |  ByteDance (字节跳动)
</li>
<li>
Chenyu Zhou (Co-advise with Prof. Yunhong Wang) |  Ant Technology Group (蚂蚁金服)
</li>  
<li>
Hanwen Zhong (NeurIPS'24, 北航优秀毕业生, 北航计算机学院优秀学位论文) |  Tencent (腾讯)
</li>
<li>
Haocheng Huang (AAAI'25) |  Yuanfudao (猿辅导)
</li>
<li>
Zhuguangyu Wu (Co-advise with Prof. Yunhong Wang) (2 CVPR'25、ECCV'24, 北航优秀毕业生, 北航优秀学位论文) |  Sense Time (商汤科技)
</li>
<li>
Bing Li (Co-advise with Prof. Di Huang) (NeurIPS'24、IJCAI'22、TIP'25)  |  Postdoc at A*STAR
</li>
<li>
Liangwei Jiang (Co-advise with Prof. Yunhong Wang) (ACM MM'23, 北航计算机学院优秀学位论文)  |  Ant Technology Group (蚂蚁金服)
</li>
<li>
Bowei Du (Co-advise with Prof. Di Huang) (CVPR'23, 北航优秀学位论文)  |  Alibaba Group (阿里巴巴集团)
</li>
<li>
Zimeng Wu (Undergraduate)  |  Ph.D Candidate in BUAA
</li>
<li>
Jiaxi Wu (Co-advise with Prof. Di Huang) (2 CVPR'22)  |  Horizon Robotics (地平线机器人)
</li>
<li>
Yecheng Huang (Co-advise with Prof. Di Huang) (AAAI'22)   
</li>
<li>
Guangyuan Zhou (Co-advise with Prof. Di Huang) (ICCV'21)  
</li>
</ul> 
<h2>Professional Activities</h2>
<ul>
<li>
TPC Member of the 39th Annual Conference on Neural Information Processing Systems (NeurIPS), San Diego, USA, 2025.
</li>
<li>
TPC Member of the 20th IEEE International Conference on Computer Vision (ICCV), Hawaii, USA, 2025.
</li>
<li>
TPC Member of the 42nd International Conference on Machine Learning (ICML), Vancouver, Canada, 2025.
</li>
<li>
TPC Member of the 43rd IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Nashville, USA, 2025.
</li>
<li>
TPC Member of the 34th International Joint Conference on Artificial Intelligence (IJCAI), Montreal, Canada, 2025.
</li>
<li>
TPC Member of the 30th International Conference on Learning Representations (ICLR), Singapore, 2025.
</li>
<li>
TPC Member of the 27th IEEE Internatinal Joint Conference on Biometrics (IJCB), New York, USA, 2024.
</li>
<li>
TPC Member of the 38th Annual Conference on Neural Information Processing Systems (NeurIPS), Vancouver, Canada, 2024.
</li>
<li>
TPC Member of the 27th European Conference on Artificial Intelligence (ECAI), Santiago de Compostela, Spain, 2024.
</li>
<li>
TPC Member of the 17th Asian Conference on Computer Vision (ACCV), Hanoi, Vietnam, 2024.
</li>
<li>
TPC Member of the 42nd IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Seattle, USA, 2024.
</li>
<li>
TPC Member of the 18th European Conference on Computer Vision (ECCV), MiCo Milano, Italy, 2024.
</li>
<li>
TPC Member of the 27th International Conference on Pattern Recognition (ICPR), Kolkata, India, 2024.
</li>
</ul>  
<h2>Projects</h2>
<ul>
<li>
Research on Model Lightweighting and Efficient Inference Techniques for In-vehicle Large Vision-Language-Action Models. Supported by BNSF (2025-2027), Key Participant.
</li>
<li>
Efficient Visual Object Search Based on Unmanned Aerial Vehicles. Supported by BNSF (2024-2026), PI.
</li>
<li>
Research on Efficient UAV Based Autonomous Object Recognition in Complex Environment. Supported by ASFC (2023-2025), PI.
</li>
<li>
Fine-grained Visual Perception. Supported by Research Program of State Key Laboratory of Virtual Reality Technology and Systems (2023-2024), PI.
</li>
<li>
Efficient Compact Representation Learning for Accurate Visual Search in Open Environments. Supported by NSFC (2023-2025), PI.
</li>
</ul>
<h2>Courses</h2>
<h3>2025</h3>
<ul>
<li>
Machine Learning, Graduate course, Fall
</li>
<li>
Writing and Presenting for Computer Science for Ms. Students, Graduate course, Fall
</li>
<li>
Mini Course on Scientific Research (Intelligent Visual Object Search Based on Deep Learning), Undergraduate course, Fall
</li>
<li>
Machine Learning, Undergraduate course, Spring
</li>
<li>
Introduction to Artificial Intelligence, Undergraduate course, Spring
</li>
<li>
Mini Course on Scientific Research (Intelligent Visual Object Search Based on Deep Learning), Undergraduate course, Spring
</li>
<li>
Writing and Presenting for Computer Science for PhD Students, Graduate course, Spring
</li>
</ul>
<h3>2024</h3>
<ul>
<li>
Introduction to Machine Learning, Undergraduate course, Fall
</li>
<li>
Machine Learning, Graduate course, Fall
</li>
<li>
Introduction to Artificial Intelligence, Undergraduate course, Spring
</li>
<li>
Mini Course on Scientific Research (Intelligent Visual Object Search Based on Deep Learning), Undergraduate course, Spring and Fall
</li>
<li>
Writing and Presenting for Computer Science, Graduate course, Spring and Fall
</li>
</ul>
<h3>2023</h3>
<ul>
<li>
Introduction to Artificial Intelligence, Undergraduate course, Spring
</li>
<li>
Mini Course on Scientific Research, Undergraduate course, Spring and Fall
</li>
<li>
Introduction to Machine Learning, Undergraduate course, Fall
</li>
<li>
Writing and Presenting for Computer Science, Graduate course, Spring and Fall
</li>
<li>
Machine Learning, Graduate course, Fall
</li>
</ul>
</h2>
<h2>
“积土成山，风雨兴焉；积水成渊，蛟龙生焉；积善成德，而神明自得，圣心备焉。故不积跬步，无以至千里；不积小流，无以成江海。骐骥一跃，不能十步；驽马十驾，功在不舍。锲而舍之，朽木不折；锲而不舍，金石可镂。”—荀子《劝学》
</h2>
<a href="https://info.flagcounter.com/oRS3"><img src="https://s01.flagcounter.com/map/oRS3/size_s/txt_000000/border_CCCCCC/pageviews_1/viewers_0/flags_0/" alt="Flag Counter" border="0"></a>
<div id="footer">
<div id="footer-text">
<br>Page generated 2022-08-01, by <a href="https://dr-jiaxin-chen.github.io/page/">Jiaxin Chen</a>.
</div>
</div>
</div>
</body>
</html>
